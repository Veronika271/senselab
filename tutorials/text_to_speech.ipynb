{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to speech\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensein/senselab/blob/main/tutorials/text_to_speech.ipynb)\n",
    "\n",
    "This tutorial demonstrates how to use the `synthesize_texts` function to convert pieces of text into audio files efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, let's import the necessary libraries and the function we'll be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from senselab.utils.data_structures.model import TorchModel\n",
    "from senselab.utils.data_structures.language import Language\n",
    "from senselab.utils.data_structures.device import DeviceType\n",
    "from senselab.audio.data_structures.audio import Audio\n",
    "from senselab.audio.tasks.preprocessing.preprocessing import resample_audios, downmix_audios_to_mono, extract_segments\n",
    "from senselab.audio.tasks.plotting.plotting import play_audio\n",
    "from senselab.audio.tasks.text_to_speech import synthesize_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the TTS model, the language and the preferred device\n",
    "Let's initialize the model we want to use (remember to specify both the ```path_or_uri``` and the ```revision``` for reproducibility purposes), the language of the text we want to synthetize, and the device we prefer. In this tutorial, we are going to use [```mars5```](https://github.com/Camb-ai/MARS5-TTS), which only works for English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TorchModel(path_or_uri=\"Camb-ai/mars5-tts\", revision=\"master\")\n",
    "language = Language(language_code=\"en\")\n",
    "device = DeviceType.CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Target Audio File\n",
    "Now let's load and process the audio file that contains the voice we want to target as part of our text-to-speech process. We do segment just the first second of audio since that contains 1 speaker only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = Audio.from_filepath(\"../src/tests/data_for_testing/audio_48khz_mono_16bits.wav\")\n",
    "ground_truth = \"This is Peter.\"\n",
    "audio = extract_segments([(audio, [(0.0, 1.0)])])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Let's preprocess the audio data to make it suitable with the TTS model characteristics that we can find in the model card in the HuggingFace Hub. In particular, for our example model we need the audio to be sampled at 24kHz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = downmix_audios_to_mono([audio])[0]\n",
    "audio = resample_audios([audio], 24000)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is how it sounds our target audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(audio)\n",
    "print(\"Ground truth:\", ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthesis\n",
    "Let's finally synthetize the audio. \n",
    "\n",
    "Note: If you want to specify more params and customize the process, you can do it. For more details, see the [**dedicated documentation**](https://sensein.group/senselab/senselab/audio/tasks/text_to_speech.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = synthesize_texts(texts=[\"Hello, world. It's nice to meet you.\"], \n",
    "                 target=[[audio, ground_truth]],\n",
    "                 model=model,\n",
    "                 language=language\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is the output audio of our tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play_audio(res[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "senselab-q-A9GWa9-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
