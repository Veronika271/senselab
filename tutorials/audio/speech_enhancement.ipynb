{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Speech enhancement\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensein/senselab/blob/main/tutorials/audio/speech_enhancement.ipynb)\n",
                "\n",
                "This tutorial demonstrates how to use the `enhance_audios` function to enhance speech signals.\n",
                "\n",
                "We will show you how to use the [Speformer model (speechbrain/sepformer-wham16k-enhancement)](https://huggingface.co/speechbrain/sepformer-wham16k-enhancement)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/om2/user/mbsilva/anaconda/envs/senselab/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n",
                        "A newer version (0.25) of nipype/pydra is available. You are using 0.23\n"
                    ]
                }
            ],
            "source": [
                "# Import the necessary modules from the Senselab package for audio processing\n",
                "from senselab.audio.data_structures import Audio\n",
                "from senselab.audio.tasks.plotting.plotting import play_audio\n",
                "from senselab.audio.tasks.preprocessing import resample_audios\n",
                "from senselab.audio.tasks.speech_enhancement import enhance_audios\n",
                "from senselab.utils.data_structures import DeviceType, SpeechBrainModel\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "SyntaxError",
                    "evalue": "unmatched ']' (2103794072.py, line 5)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    audio = Audio.from_filepath(\"tutorial_audio_files/audio_48khz_mono_16bits.wav\")]\u001b[0m\n\u001b[0m                                                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ']'\n"
                    ]
                }
            ],
            "source": [
                "!mkdir -p tutorial_audio_files\n",
                "!wget -O tutorial_audio_files/audio_48khz_mono_16bits.wav https://github.com/sensein/senselab/raw/main/src/tests/data_for_testing/audio_48khz_mono_16bits.wav\n",
                "\n",
                "# Load an audio file from the specified file path\n",
                "audio = Audio.from_filepath(\"tutorial_audio_files/audio_48khz_mono_16bits.wav\")\n",
                "\n",
                "# Resample the audio to 16kHz to match the model's expected input format\n",
                "audio = resample_audios([audio], 16000)[0]\n",
                "\n",
                "# Play the resampled audio to verify the preprocessing step\n",
                "play_audio(audio)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load a pre-trained speech enhancement model from SpeechBrain (sepformer-wham16k-enhancement)\n",
                "model = SpeechBrainModel(path_or_uri=\"speechbrain/sepformer-wham16k-enhancement\", revision=\"main\")\n",
                "\n",
                "# Initialize the device for running the model\n",
                "device = DeviceType.CPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Enhance the audio using the loaded model, running the process on the specified device\n",
                "enhanced_audio = enhance_audios(\n",
                "            audios=[audio], \n",
                "            model=model,\n",
                "            device=device\n",
                "        )[0]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Play the enhanced audio to hear the result after speech enhancement\n",
                "play_audio(enhanced_audio)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "senselab-lOUhtavG-py3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
