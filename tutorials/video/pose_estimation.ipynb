{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Pose Estimation\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sensein/senselab/blob/main/tutorials/video/pose_estimation.ipynb)\n",
                "\n",
                "This tutorial demonstrates how to use Senselab's Pose Estimation API for estimating human poses in images. Senselab supports multiple pose estimation backends, such as MediaPipe and YOLO."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup\n",
                "\n",
                "Let's get started by installing Senselab and importing the necessary modules from Senselab for processing images and performing pose estimation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "outputs": [],
            "source": [
                "%pip install senselab"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "outputs": [],
            "source": [
                "from senselab.video.tasks.pose_estimation import MediaPipePoseEstimator, YOLOPoseEstimator\n",
                "from senselab.video.data_structures.pose import ImagePose"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "outputs": [],
            "source": [
                "!mkdir -p tutorial_images\n",
                "!wget -O tutorial_images/no_people.jpg https://github.com/sensein/senselab/raw/main/src/tests/data_for_testing/pose_data/no_people.jpg\n",
                "!wget -O tutorial_images/single_person.jpg https://github.com/sensein/senselab/raw/main/src/tests/data_for_testing/pose_data/single_person.jpg\n",
                "!wget -O tutorial_images/three_people.jpg https://github.com/sensein/senselab/raw/main/src/tests/data_for_testing/pose_data/three_people.jpg"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## MediaPipe Pose Estimation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Initialize MediaPipe Estimator\n",
                "Let's initialize the MediaPipe Pose Estimator. We will use the \"full\" model for this tutorial.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "outputs": [],
            "source": [
                "mp_estimator = MediaPipePoseEstimator(model_type=\"full\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Perform Pose Estimation\n",
                "Now, let's perform pose estimation on the example image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "outputs": [],
            "source": [
                "image_path = \"tutorial_images/single_person.jpg\"\n",
                "result = mp_estimator.estimate_from_path(image_path)\n",
                "\n",
                "# Check the output\n",
                "print(f\"Number of individuals detected: {len(result.individuals)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize Results\n",
                "To visualize the estimated poses, use Senselab's built-in plotting utilities."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "outputs": [],
            "source": [
                "#TODO"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## YOLO Pose Estimation"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Initialize YOLO Estimator\n",
                "Next, let's initialize the YOLO Pose Estimator using the \"11n\" model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "outputs": [],
            "source": [
                "yolo_estimator = YOLOPoseEstimator(model=\"8n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Perform Pose Estimation\n",
                "Run the YOLO model on the same example image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "outputs": [],
            "source": [
                "result = yolo_estimator.estimate_from_path(image_path)\n",
                "\n",
                "# Check the output\n",
                "print(f\"Number of individuals detected: {len(result.individuals)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualize Results\n",
                "Plot the YOLO-estimated poses on the image."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "outputs": [],
            "source": [
                "plot_image_pose(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Extended Cases"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Estimating Poses in Multiple-Person Images\n",
                "\n",
                "You can specify the maximum number of individuals to detect using the num_individuals parameter (MediaPipe only):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "outputs": [],
            "source": [
                "multi_person_image = \"tutorial_images/three_people.jpg\"\n",
                "result = mp_estimator.estimate_from_path(multi_person_image, num_individuals=3)\n",
                "plot_image_pose(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Handling No Person Detected\n",
                "If no person is detected in the image, the output will have zero individuals."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "vscode": {
                    "languageId": "plaintext"
                }
            },
            "outputs": [],
            "source": [
                "no_person_image = \"tutorial_images/no_people.jpeg\"\n",
                "result = mp_estimator.estimate_from_path(no_person_image)\n",
                "\n",
                "if len(result.individuals) == 0:\n",
                "    print(\"No individuals detected in the image.\")"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
